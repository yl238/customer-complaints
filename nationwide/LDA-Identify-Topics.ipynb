{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sueliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from preprocess.clean_and_tokenize import clean_and_tokenize_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_topic_map(map_file):\n",
    "    \"\"\"Read topic to description map file as an Excel file and convert to dictionary\n",
    "    \"\"\"\n",
    "    topic_map = pd.read_excel(map_file).dropna()[['ID', 'Summarized Topic Name']]\n",
    "    topic_map['ID'] = topic_map['ID'].astype(int)\n",
    "    topic_map = topic_map.set_index('ID')\n",
    "    topic_map = list(topic_map.to_dict().values())[0]\n",
    "    return topic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_complaint_topics(lda_model, vectorizer, complaints_df, \n",
    "                               text_field = 'compliant_text_cleaned',\n",
    "                               n_topics=45, topic_map=None,\n",
    "                               top_n=5):\n",
    "    \"\"\"\n",
    "    Predict the top_n topics with probability.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lda_model - Latent Dirichlet Model trained on US data\n",
    "    vectorizer - CountVectorizer trained on US data\n",
    "    complaint_df - Pandas Dataframe: all complaint info as a Dataframe\n",
    "    text_field - string: the field name containing complaint text\n",
    "    \n",
    "    n_topics - int: number of topics in the US data\n",
    "    topic_map - dict: topic to description map\n",
    "    top_n - int: top N topics to be displayed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: {'original_narrative': text, \n",
    "           'topics': {topic_idx', 'topic_name', 'topic_prob'}}\n",
    "    \"\"\"\n",
    "    if topic_map is None:\n",
    "        print('Need topic index to description mapping!!! Stop now and check!!!')\n",
    "        return\n",
    "    \n",
    "    complaints_df['cleaned'] = complaints_df[text_field].apply(clean_and_tokenize_one)\n",
    "\n",
    "    vectorized = vectorizer.transform(complaints_df['cleaned'])\n",
    "    topics = lda_model.transform(vectorized)\n",
    "    \n",
    "    all_output = []\n",
    "    for i in range(topics.shape[0]):\n",
    "        output = dict()\n",
    "        output['Original narrative'] = complaints_df[text_field][i]\n",
    "        topic_indices = np.argsort(topics[i, :])[::-1]\n",
    "        topic_prob = np.sort(topics[i, :])[::-1]\n",
    "    \n",
    "        topics_data = {}\n",
    "        for importance_count, [idx, prob] in enumerate(list(zip(topic_indices, topic_prob))[:top_n]):\n",
    "            topics_data[importance_count] = {'topic_name': topic_map[int(idx)],\n",
    "                                             'topic_prob': prob}\n",
    "        output['topics'] = topics_data\n",
    "        all_output.append(output)\n",
    "    return all_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sueliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python LDA_identify_topics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Vectorizer Trained on original US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lda_45_topics.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "lda_model = data['model']\n",
    "vectorizer = data['vectorizer']\n",
    "\n",
    "topic_map = gen_topic_map('topics_matching.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = pd.read_csv('Nationwide_complaints.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict_complaint_topics(lda_model, vectorizer, complaints_df, \n",
    "                               text_field = 'compliant_text_cleaned',\n",
    "                               n_topics=45, topic_map=topic_map,\n",
    "                               top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('nationwide_identified_topics.json', 'w') as fout:\n",
    "    json.dump(output, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nationwide_identified_topics.json', 'r') as f:\n",
    "    outputs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely awful bank! I have moved my account back to Santander who were so much better. I only moved over to try to gain advantage from the new account offer and savings account interest.Nationwide have done absolutely nothing to help resolve an issue I had with an online fraudulent transaction, other than waste my time by telling me that I could not report the transaction for 30 days, then they wasted my time by requesting the same information which I had already submitted over and over again..and now finally they have closed the dispute because it has gone over the time they allot to investigating a fraudulent transactionTheir customer service is an absolute farce and utter disgrace! I intend to report them to all the relevant authorities.Whatever you do, do not open an account with them. They are not interested in your wellbeing at all.DISGRACEFUL!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Customer service</td>\n",
       "      <td>0.2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Opening or closing account</td>\n",
       "      <td>0.22374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fraudulent transaction</td>\n",
       "      <td>0.15004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Customer support</td>\n",
       "      <td>0.135509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Interest rates</td>\n",
       "      <td>0.0571193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   topic_name topic_prob\n",
       "0            Customer service     0.2694\n",
       "1  Opening or closing account    0.22374\n",
       "2      Fraudulent transaction    0.15004\n",
       "3            Customer support   0.135509\n",
       "4              Interest rates  0.0571193"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 35\n",
    "print(outputs[idx]['Original narrative'])\n",
    "pd.DataFrame.from_dict(outputs[idx]['topics']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
