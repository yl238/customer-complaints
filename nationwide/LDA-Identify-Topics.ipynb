{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sueliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from preprocess.clean_and_tokenize import clean_and_tokenize_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Vectorizer Trained on original US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lda_45_topics.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "lda_model = data['model']\n",
    "vectorizer = data['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_complaint_topics(lda_model, vectorizer, complaints_df, \n",
    "                               text_field = 'compliant_text_cleaned',\n",
    "                               n_topics=45, topic_map=None,\n",
    "                               top_n=5):\n",
    "    \"\"\"\n",
    "    Predict the top_n topics with probability.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lda_model - Latent Dirichlet Model trained on US data\n",
    "    vectorizer - CountVectorizer trained on US data\n",
    "    complaint_df - Pandas Dataframe: all complaint info as a Dataframe\n",
    "    text_field - string: the field name containing complaint text\n",
    "    \n",
    "    n_topics - int: number of topics in the US data\n",
    "    topic_map - dict: topic to description map\n",
    "    top_n - int: top N topics to be displayed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: {'original_narrative': text, \n",
    "           'topics': {topic_idx', 'topic_name', 'topic_prob'}}\n",
    "    \"\"\"\n",
    "    if topic_map is None:\n",
    "        print('Need topic index to description mapping!!! Stop now and check!!!')\n",
    "        return\n",
    "    \n",
    "    complaints_df['cleaned'] = complaints_df[text_field].apply(clean_and_tokenize_one)\n",
    "\n",
    "    vectorized = vectorizer.transform(complaints_df['cleaned'])\n",
    "    topics = lda_model.transform(vectorized)\n",
    "    \n",
    "    all_output = []\n",
    "    for i in range(topics.shape[0]):\n",
    "        output = dict()\n",
    "        output['Original narrative'] = complaints_df[text_field][i]\n",
    "        topic_indices = np.argsort(topics[i, :])[::-1]\n",
    "        topic_prob = np.sort(topics[i, :])[::-1]\n",
    "    \n",
    "        topics_data = {}\n",
    "        for importance_count, [idx, prob] in enumerate(list(zip(topic_indices, topic_prob))[:top_n]):\n",
    "            topics_data[importance_count] = {'topic_idx': int(idx), \n",
    "                           'topic_name': topic_map[int(idx)],\n",
    "                           'topic_prob': prob}\n",
    "        output['topics'] = topics_data\n",
    "        all_output.append(output)\n",
    "    return all_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_topic_map(map_file):\n",
    "    topic_map = pd.read_excel(map_file).dropna()[['ID', 'Summarized Topic Name']]\n",
    "    topic_map['ID'] = topic_map['ID'].astype(int)\n",
    "    topic_map = topic_map.set_index('ID')\n",
    "    topic_map = list(topic_map.to_dict().values())[0]\n",
    "    return topic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_map = gen_topic_map('topics_matching.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = pd.read_csv('Nationwide_complaints.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict_complaint_topics(lda_model, vectorizer, complaints_df, \n",
    "                               text_field = 'compliant_text_cleaned',\n",
    "                               n_topics=45, topic_map=topic_map,\n",
    "                               top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('identified_topics.json', 'w') as fout:\n",
    "    json.dump(output, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original narrative': \"Beware. Nationwide has a new policy of closing down the accounts of customers who complain a certain amount of times. Nationwide doesn't take into account whether the complaints have been upheld by themselves.\", 'topics': {'0': {'topic_idx': 29, 'topic_name': 'Opening or closing account', 'topic_prob': 0.45583688482477036}, '1': {'topic_idx': 35, 'topic_name': 'Insurance and customer protections', 'topic_prob': 0.1490589012907176}, '2': {'topic_idx': 28, 'topic_name': 'Legal complaints', 'topic_prob': 0.07535485718420624}, '3': {'topic_idx': 14, 'topic_name': 'Customer service', 'topic_prob': 0.05519251344301094}, '4': {'topic_idx': 16, 'topic_name': 'Terms and conditions of accounts', 'topic_prob': 0.006455277167451151}}}\n"
     ]
    }
   ],
   "source": [
    "with open('identified_topics.json', 'r') as f:\n",
    "    outputs = json.load(f)\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
