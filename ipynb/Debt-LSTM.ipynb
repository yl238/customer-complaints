{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/debt_only.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df[['Complaint ID', 'tokenized_text', 'Issue']].dropna()\n",
    "model_df = model_df[model_df['tokenized_text'].str.len() >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attempts to collect debt not owed                                23867\n",
       "Cont'd attempts collect debt not owed                            17376\n",
       "Communication tactics                                            12600\n",
       "Written notification about debt                                  10689\n",
       "False statements or representation                                9510\n",
       "Disclosure verification of debt                                   7580\n",
       "Took or threatened to take negative or legal action               6611\n",
       "Taking/threatening an illegal action                              2934\n",
       "Improper contact or sharing of info                               2910\n",
       "Threatened to contact someone or share information improperly     1702\n",
       "Name: Issue, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.Issue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev_map = {\n",
    "    'Attempts to collect debt not owed' : 'DNO',\n",
    "    'Communication tactics': 'CT',\n",
    "    \"Cont'd attempts collect debt not owed\": 'CDNO',\n",
    "    \"Disclosure verification of debt\": 'DV',\n",
    "    \"False statements or representation\": 'FS',\n",
    "    \"Improper contact or sharing of info\": 'IC',\n",
    "    \"Taking/threatening an illegal action\": 'TIA',\n",
    "    \"Threatened to contact someone or share information improperly\": 'IC',\n",
    "    \"Took or threatened to take negative or legal action\": 'TNA',\n",
    "    \"Written notification about debt\": 'WN'\n",
    "}\n",
    "model_df['target'] = model_df['Issue'].apply(lambda i: abbrev_map[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_types = ['DNO', 'CT', 'WN', 'FS', 'DV', 'TNA']\n",
    "model_df = model_df[model_df['target'].isin(valid_types)]\n",
    "targets = sorted(model_df['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNO    0.336833\n",
       "CT     0.177823\n",
       "WN     0.150853\n",
       "FS     0.134214\n",
       "DV     0.106976\n",
       "TNA    0.093301\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df['target'].value_counts() / len(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SpatialDropout1D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44091 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(model_df['tokenized_text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor:  (70857, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(model_df['tokenized_text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor:  (70857, 6)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(model_df['target']).values\n",
    "print('Shape of label tensor: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63771, 250) (63771, 6)\n",
      "(7086, 250) (7086, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 5,081,006\n",
      "Trainable params: 5,081,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sueliu/Mudano/customer-complaints/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 57393 samples, validate on 6378 samples\n",
      "Epoch 1/5\n",
      "57393/57393 [==============================] - 241s 4ms/step - loss: 1.3936 - accuracy: 0.4678 - val_loss: 1.2920 - val_accuracy: 0.5151\n",
      "Epoch 2/5\n",
      "57393/57393 [==============================] - 243s 4ms/step - loss: 1.2356 - accuracy: 0.5346 - val_loss: 1.2597 - val_accuracy: 0.5279\n",
      "Epoch 3/5\n",
      "57393/57393 [==============================] - 249s 4ms/step - loss: 1.1430 - accuracy: 0.5759 - val_loss: 1.2309 - val_accuracy: 0.5436\n",
      "Epoch 4/5\n",
      "57393/57393 [==============================] - 273s 5ms/step - loss: 1.0592 - accuracy: 0.6116 - val_loss: 1.2346 - val_accuracy: 0.5452\n",
      "Epoch 5/5\n",
      "57393/57393 [==============================] - 241s 4ms/step - loss: 0.9936 - accuracy: 0.6392 - val_loss: 1.2694 - val_accuracy: 0.5387\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, batch_size=batch_size,validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [targets[i] for i in np.argmax(y_test, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [targets[i] for i in np.argmax(pred, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CT       0.70      0.72      0.71      1187\n",
      "         DNO       0.60      0.71      0.65      2462\n",
      "          DV       0.43      0.31      0.36       760\n",
      "          FS       0.50      0.22      0.30       995\n",
      "         TNA       0.35      0.46      0.40       657\n",
      "          WN       0.43      0.47      0.45      1025\n",
      "\n",
      "    accuracy                           0.54      7086\n",
      "   macro avg       0.50      0.48      0.48      7086\n",
      "weighted avg       0.54      0.54      0.53      7086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
