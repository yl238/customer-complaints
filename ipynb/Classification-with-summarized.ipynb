{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We check if there has been improvement in classification results with the amount we've converted \n",
    "We've summarized about half of the data now, but it's enough to make a start on classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/product_merged.csv'\n",
    "df = pd.read_csv(file, usecols=['Complaint ID', 'Product', 'Issue', 'Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../output/summary_1.txt'\n",
    "text = []\n",
    "with open(text_file, 'r') as f:\n",
    "    for line in f:\n",
    "        text.append(line)\n",
    "text_file = '../output/summary_100000.txt'\n",
    "with open(text_file, 'r') as f:\n",
    "    for line in f:\n",
    "        text.append(line)\n",
    "text_file = '../output/summary_200000.txt'\n",
    "with open(text_file, 'r') as f:\n",
    "    for line in f:\n",
    "        text.append(line)\n",
    "text_file = '../output/summary_300000.txt'\n",
    "with open(text_file, 'r') as f:\n",
    "    for line in f:\n",
    "        text.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_newlines = [re.sub(r'\\n', '', doc) for doc in text]\n",
    "summary_df = pd.DataFrame()\n",
    "summary_df['summary'] = no_newlines\n",
    "summary_df.to_csv('../output/all_summaries.csv')\n",
    "df['summarized'] = no_newlines\n",
    "df.to_csv('../output/with_summarized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "special = re.compile(r'http\\S+|www\\S+|[^a-zA-Z ]+|xx+')\n",
    "docs_orig = [' '.join(special.sub('', doc.lower()).split()) for doc in df['Consumer complaint narrative'].values]\n",
    "docs_summ = [' '.join(special.sub('', doc.lower()).split()) for doc in df['summarized'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_orig = []\n",
    "for doc in nlp.pipe(docs_orig, disable=['tagger', 'parser', 'ner']):\n",
    "    tokenized_orig.append(\" \".join(token.lemma_.lower() for token in doc if not token.is_stop and not token.is_space \\\n",
    "            and not token.is_punct and not token.like_num))\n",
    "    \n",
    "tokenized_summ = []\n",
    "for doc in nlp.pipe(docs_summ, disable=['tagger', 'parser', 'ner']):\n",
    "    tokenized_summ.append(\" \".join(token.lemma_.lower() for token in doc if not token.is_stop and not token.is_space \\\n",
    "            and not token.is_punct and not token.like_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs_orig\n",
    "del docs_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sueliu/Mudano/customer-complaints/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/sueliu/Mudano/customer-complaints/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['orig'] = tokenized_orig\n",
    "df['summ'] = tokenized_summ\n",
    "df = valid_df.dropna()\n",
    "df.to_csv('../output/with_summarized_tokenized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now some ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = valid_df[valid_df.Product.isin(valid_targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(valid_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, X_val_orig = train_df['orig'].values, val_df['orig'].values\n",
    "X_train_summ, X_val_summ = train_df['summ'].values, val_df['summ'].values\n",
    "y_train, y_val = train_df['Product'].values, val_df['Product'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fall financial hardship lose job file bankruptcy chapter discharge time child afford payment trustee month mortgage miss approx mortgage payment foreclosure proceed begin occur anytime protect automatic stay bankruptcy law well fargo mortgage approve remodification new federal law fha loan charge exorbitantly high capitalize interest note new money page honest naively impression principal balance remain file chapter child keep house important accept remodification sign document local well fargo branch know hit hard delinquent interest unknown fee feel well gouge place underwater loan feel offer well finance rate new money cap low annual rate potential difference month big deal family thank advance help provide matt sincerely'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank america report equity line derogatory item way report credit bureau late adversely affect credit score unable refinance property value property drop credit report fault drop credit report'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_summ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=1000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=1000)\n",
    "tfidf_vect.fit(X_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig_tfidf = tfidf_vect.transform(X_train_orig)\n",
    "X_val_orig_tfidf = tfidf_vect.transform(X_val_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect2 = TfidfVectorizer(analyzer='word', max_features=1000)\n",
    "tfidf_vect2.fit(X_train_summ)\n",
    "X_train_summ_tfidf = tfidf_vect2.transform(X_train_summ)\n",
    "X_val_summ_tfidf = tfidf_vect2.transform(X_val_summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=500, multi_class='auto', n_jobs=3, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1.0, max_iter=500, class_weight='balanced', multi_class='auto', solver='lbfgs', n_jobs=3)\n",
    "lr.fit(X_train_orig_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_targets = ['Credit card or prepaid card', 'Debt collection', 'Mortgage', \n",
    "                 'Payday loan, title loan, or personal loan', 'Student loan']\n",
    "targets = sorted(val_df['Product'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orig = lr.predict(X_val_orig_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "              Credit card or prepaid card       0.58      0.91      0.71      1419\n",
      "                          Debt collection       0.97      0.85      0.91     15500\n",
      "                                 Mortgage       0.96      0.93      0.94      9019\n",
      "Payday loan, title loan, or personal loan       0.38      0.80      0.52      1077\n",
      "                             Student loan       0.89      0.91      0.90      3692\n",
      "\n",
      "                                 accuracy                           0.88     30707\n",
      "                                macro avg       0.75      0.88      0.79     30707\n",
      "                             weighted avg       0.92      0.88      0.89     30707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, pred_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=500, multi_class='auto', n_jobs=3, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_summ = LogisticRegression(C=1.0, max_iter=500, class_weight='balanced', multi_class='auto', solver='lbfgs', n_jobs=3)\n",
    "lr_summ.fit(X_train_summ_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_summ = lr.predict(X_val_summ_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "              Credit card or prepaid card       0.20      0.32      0.25      1419\n",
      "                          Debt collection       0.54      0.43      0.48     15500\n",
      "                                 Mortgage       0.31      0.35      0.33      9019\n",
      "Payday loan, title loan, or personal loan       0.11      0.22      0.14      1077\n",
      "                             Student loan       0.14      0.13      0.14      3692\n",
      "\n",
      "                                 accuracy                           0.36     30707\n",
      "                                macro avg       0.26      0.29      0.27     30707\n",
      "                             weighted avg       0.39      0.36      0.37     30707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, pred_summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
